---
title: "Beyond Bias - Data Compile code"
author: "A.G. Mitchell"
date: "2022-10-19"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(reshape2)
library(glmmTMB)
library(ggplot2)
library(plyr)
library(lme4)
```

# Setting paths for raw data and analysis
```{r}
dPath <- '/Users/au706616/Documents/Experiments/PIPTOT/LBTraw'
aPath <- '/Users/au706616/Documents/Experiments/PIPTOT/analysis/'

datname <- 'LBTraw_final.csv'
dat2name <- 'LBTraw_final2.csv'
qualname <- 'QUALraw_final2.csv'

# load raw and qual data
bisectData <- read.csv(file.path(dPath,datname)) 
bisect2Data <- read.csv(file.path(dPath,dat2name)) #another data set with extra 85 participants (due to data-loss)
qualData <- read.csv(file.path(dPath,qualname)) 

# flag first and second recruitment rounds
bisectData$recruit <- 1
bisect2Data$recruit <- 2
# rbind bisect data-sets
bisectData <- rbind(bisectData, bisect2Data)
```

# Main data load and compile
```{r}
# first get an idea of all participants (prolific IDs)
nres <- aggregate(acc~prolific_id, length, data=bisectData)
length(nres$prolific_id)

# n particiants removed who failed audio check/too few trials
nAudio <- dplyr::filter(nres, acc < 200)
# id_x <- nAudio$prolific_id #identifying participants to be removed

# count void trials - identify excessive
void <- dplyr::filter(bisectData, void_trial == 1)
nVoid <- aggregate(void_trial~prolific_id, length, data=void)

# narrow down data-frame to relevant columns only - putting important first
dat <- bisectData[, c(224,6,11,12,26,289,211,212,274,275,214,36,37,46,89,164,165,206,207,
                          208,216:218,222,223,225,228,229,237,251,352,356,319,321,322,386,388,
                      131,385,389)]
# data for calibration check, seperate from main df
calib_dat <- bisectData[, c(224,17:34,172:189,281,287,208)]
```

# Organise qualitative data
```{r}
## Qualitative data
# Load and merge with qualitative data
## Qualitative data
qualData <- read.csv(file.path(dPath,qualname)) 

# first, some renaming and reorganising of the qual data
names(qualData)[1] <- 'consent'
names(qualData)[2] <- 'prolific_id'
names(qualData)[3] <- 'gender'
names(qualData)[4] <- 'age'

# split off EHI
EHI <- qualData[, c(2,6:15)]
qualData <- qualData[, c(2,1,3,4)]

# merge with bisection data using jatos IDs to obtain prolific id, to merge data-frames
dat <- merge(qualData, dat, by = 'prolific_id')
calib_dat <- merge(qualData, calib_dat, by = 'prolific_id')
# remove unecessary columns from calib10 - to match other calibration
calib_dat <- calib_dat[, -c(2,3,4)]
```

# First 10 participants load, compile and add to other data
This is slightly different than above because PIDs were not recorded for the first 10
participants. Have manually matched all JATOS IDs with PIDs

Run the same steps as above on these data
```{r}
# do the same as above for the first 10 participants (collected seperately)
# then combine their data
dat10name <- 'LBTraw_first10.csv'
qual10name <- 'QUALraw_first10.csv'

# first only load the raw data because demographic is a little useless at this stage
bisect10Data <- read.csv(file.path(dPath,dat10name)) 
bisect10Data$recruit <- 1 

# same filtering as above
# first get an idea of all participants (prolific IDs)
nres10 <- aggregate(acc~jatosStudyResultId, length, data=bisect10Data)
length(nres10$jatosStudyResultId)

# n particiants removed who failed audio check/too few trials
nAudio10 <- dplyr::filter(nres10, acc < 200)
#id_x10 <- nAudio10$jatosStudyResultId #identifying participants to be removed
# count void trials
void10 <- dplyr::filter(bisect10Data, void_trial == 1)

# narrow down data-frame for correct columns only
dat10 <- bisect10Data[, c(6,11,12,26,271,201,202,256,257,204,36,37,45,81,154,155,196,197,
                          198,206:208,212,213,215,218,219,224,237,326,330,294,296,297,
                          359,361,123,358,362)]
calib10 <- bisect10Data[, c(17:34,162:179,263,269,198)]

## Qualitative data
qual10Data <- read.csv(file.path(dPath,qual10name)) 
# flag PIDs with no code & no data
nPID <- c('611e1eee7989eadcee23045c', '6025df3ed83eed206142329a', '6130d846086f43ecd225d128')
# qualitative data
# first, some renaming and reorganising of the qual data
names(qual10Data)[1] <- 'consent'
names(qual10Data)[2] <- 'prolific_id'
names(qual10Data)[3] <- 'gender'
names(qual10Data)[4] <- 'age'
# remove no code PIDs from quantitative
qual10Data <- filter(qual10Data, !(prolific_id %in% nPID))

# split off EHI
EHI10 <- qual10Data[, c(2,6:15)]
qual10Data <- qual10Data[, c(2,1,3,4,16)]

# merge with bisection data using jatos IDs to obtain prolific id, to merge data-frames
dat10 <- merge(qual10Data, dat10, by = 'jatosStudyResultId')
calib10 <- merge(qual10Data, calib10, by = 'jatosStudyResultId')
# remove unecessary columns from calib10 - to match other calibration
calib10 <- calib10[, -c(3,4,5)]
```

# Merge to get final dataset and final numbers!
```{r}
# Bind the smaller initial data set with the main data set to get final numbers
all_dat <- rbind(dat, dat10)
# number before calibration step
nvalid <- count(all_dat, 'prolific_id')
length(nvalid$prolific_id)

# save entire data-frame (before quality checks)
wholeFile = paste(aPath, 'LBT_all-compiled-data.csv', sep = '/')
write.csv(all_dat, wholeFile, row.names = FALSE)
```

# First data quality checks
```{r}
# filter trials so audio = passed, this removes audio step and filters participants who failed
all_dat <- dplyr::filter(all_dat, audio_passed == 1)
# then remove void trials
all_dat <- dplyr::filter(all_dat, void_trial == 0 & practice == 0)
# number of trials for each participant with void and practice removed
ndat <- aggregate(bisect_x~prolific_id, length, data=bisectData)
ndat <- ndat[order(ndat$prolific_id) ,] # order by prolific id for easy identification
# this is the actual number of participants recruited
length(ndat$prolific_id) 

# count n participants from each round
nRec1 <- all_dat %>% 
  filter(recruit == 1) %>% 
  count('prolific_id')
nRec2 <- all_dat %>% 
  filter(recruit == 2) %>% 
  count('prolific_id')

# define some key criteria
# extract variables of interest for quality checks
# first response time to line in ms
all_dat$response_time <- all_dat$time_cursor_locs - all_dat$time_line 
rt <- aggregate(response_time ~ prolific_id, mean, data = all_dat) # check it makes sense
# then length of break (in seconds)
all_dat$break_time <- (all_dat$time_break_time_stamp - all_dat$time_block_one_end)/1000
bt <- aggregate(break_time ~ prolific_id, mean, data = all_dat) # check it makes sense

# code conditions of interest - block and tone (pip)
all_dat$block <- ifelse(is.na(all_dat$count_block_2_sequence), 1, 2) #identifying block
all_dat$pip <- ifelse(all_dat$sound == 'blank', 0, 1) #if tone == 1

# PARTICIPANT REMOVAL
# there are participants that, for some reason trials have been doubled, remove those
# first order by line response count
all_dat <- all_dat[order(all_dat$count_line_mouse_response) ,]
# then prolific id
all_dat <- all_dat[order(all_dat$prolific_id) ,]
# then remove repeat trials
all_dat <- all_dat %>% 
  group_by(prolific_id) %>%
  distinct(count_line_mouse_response, .keep_all = TRUE)

# remove participants with breaks > 5 minutes
id_x <- bt$prolific_id[bt$break_time > 301] #this step removes 63 participants! 

# final audio check, correct?
finalAudio <- bisectData[bisectData$response_audio_kbd_final == 7 ,]
finalAudio <- finalAudio[, c(225,237)]
length(finalAudio$queryParams_PROLIFIC_PID)

# remove participants with long breaks from full data set
# but keep data frame that reserves these participants, because that is a lot
# DON'T RUN this step yet - need confirmation
all_dat_breaks <- filter(all_dat, !(prolific_id %in% id_x))
# n remaining participants
nvalid <- aggregate(bisect_x~prolific_id, length, data=all_dat_breaks)
length(nvalid$prolific_id)
```

# Screen calibration
Check and remove participants where calib and dot locations do not match 
Criteria:

```{r}
# Calibration check
# First bind two calibration files
calib_dat <- rbind(calib_dat, calib10)
# check numbers - do they match above
ncalib <- count(calib_dat, 'prolific_id')
length(ncalib$prolific_id) # yes, there are 142 prolific ids here (total we started with)

# only include participants that have been included in all_dat
calib_dat1 <- filter(calib_dat, (prolific_id %in% all_dat_breaks$prolific_id))
ncalib <- count(calib_dat1, 'prolific_id')
length(ncalib$prolific_id) 

# then aggregate calibration values by id - include na values in this step
calibDat <- aggregate(.~prolific_id, median, data = calib_dat1, na.action = NULL)
calibDat <- calibDat[order(calibDat$prolific_id) ,] #order, so next step works consistently

# first, identify participants more than 1/2 incomplete calibration steps
n_rows <- which(rowSums(is.na(calibDat))>9) 
#print out - to identify how many
cal_x <- calibDat$prolific_id[n_rows]

# then  participants where mid x = NA, cannot calculate bisection without it
cal_x <- append(cal_x, calibDat[is.na(calibDat$calib_loc_midy_x), 1])
length(cal_x) # this gives us 15 IDs (but there may be overlap)

# remove JATOS id
calibDat <- calibDat[, -c(40)]
# renaming so convention works for data wrangling & plotting
calibDat <- dplyr::rename(
  calibDat,
  'calib_loc_left192x_x' = 'calib_loc_left192x',
  'calib_loc_left320x_x' = 'calib_loc_left320x',
  'calib_loc_left480x_x' = 'calib_loc_left480x',
  'calib_loc_lowery_y' = 'calib_loc_lowery',
  'calib_loc_midy_y' = 'calib_loc_midy',
  'calib_loc_right192x_x' = 'calib_loc_right192x',
  'calib_loc_right320x_x' = 'calib_loc_right320x',
  'calib_loc_right480x_x' = 'calib_loc_right480x',
  'dot_loc_left192x_x' = 'dot_loc_left192x',
  'dot_loc_left320x_x' = 'dot_loc_left320x',
  'dot_loc_left480x_x' = 'dot_loc_left480x',
  'dot_loc_lowery_y' = 'dot_loc_lowery',
  'dot_loc_midy_y' = 'dot_loc_midy',
  'dot_loc_right192x_x' = 'dot_loc_right192x',
  'dot_loc_right320x_x' = 'dot_loc_right320x',
  'dot_loc_right480x_x' = 'dot_loc_right480x'
   )
              
calib_points <- reshape2::melt(calibDat, id.vars = c('prolific_id','screen_width','screen_height'),
                               value.name = 'RESP') #reshaping dataframe

# extracting important variables
calib_points$COND <- factor(substr(calib_points$variable, 1, 3))
# dot axes - x and y
substrRight <- function(x, n){
  substr(x, nchar(x)-n+1, nchar(x))
}
calib_points$AXIS <- substrRight(as.character(calib_points$variable), 1)
# then identify relevant dot locations
# dot locations
for (var in 1:length(calib_points$variable)){
  if (isTRUE(calib_points$COND[var] == 'cal')){
    calib_points$LOC[var] <- substr(calib_points$variable[var], 11, 
                                nchar(as.character(calib_points$variable[var]))-2)
  }
  else {
    calib_points$LOC[var] <- substr(calib_points$variable[var], 9, 
                                nchar(as.character(calib_points$variable[var]))-2)
  }
}
# order by prolific id
calib_points <- calib_points[order(calib_points$prolific_id) ,]
# code a seperate ID variable
calib_points$prolific_id <- as.factor(calib_points$prolific_id)
calib_points$ID <- as.character(as.numeric(calib_points$prolific_id))
calib_points$ID <- as.factor(calib_points$ID)

# plot x axis
x_plot <- ggplot(
  calib_points %>% 
    filter(AXIS == 'x'), 
  aes(RESP, 0, colour = LOC, shape = COND)) +
  geom_point() +
  scale_shape_manual(values = c(3, 1)) +
  facet_wrap(~prolific_id)
# plot y axis
y_plot <- ggplot(
  calib_points %>% 
    filter(AXIS == 'y'), 
  aes(0, RESP, colour = LOC, shape = COND)) +
  geom_point() +
  scale_shape_manual(values = c(3, 1)) +
  facet_wrap(~ID)

# FIRST - remove the participants with a lot of NAs & mid-NAs
calib_points <- filter(calib_points, !(prolific_id %in% cal_x))
n <- count(calib_points, 'prolific_id')
length(n$prolific_id)
# this step removed 11 further participants from data-set

# Regressing calibration values
# get data for linear regression
# group by COND
CLK <- dplyr::filter(calib_points, COND == 'cal')
DOT <- dplyr::filter(calib_points, COND == 'dot')
names(CLK)[5] <- 'LOC_CLK'
names(DOT)[5] <- 'LOC_DOT'

CALFIT <- merge(CLK, DOT, by = c('ID','LOC','AXIS','prolific_id',
                                 'screen_width','screen_height'))
#CALFIT <- CALFIT[, -c(5,7,8,10)]

# refit NAs
# Construct linear model based on non-NA pairs
df2 <- CALFIT %>% filter(!is.na(CALFIT$LOC_CLK))
fit <- lmList(LOC_CLK ~ LOC_DOT | prolific_id, data = df2) # 

# then predict values into diff data-frame
CALFIT2 <- CALFIT %>% 
  mutate(pred = predict(fit, .)) %>%
  # Replace NA with pred in var1
  mutate(LOC_CLK = ifelse(is.na(LOC_CLK), pred, LOC_CLK))

# this step is good but it does not change anything - boo

# plot again to see if this improves things


calibR <- read.csv(text = c('prolific_id,NUMTRIALS,RSQ'))
# recode ID
CALFIT2 <- CALFIT2[order(CALFIT2$prolific_id) ,]
CALFIT2$ID <- as.character(as.numeric(CALFIT2$prolific_id))
CALFIT2$ID <- as.factor(CALFIT2$ID)

for(ID in levels(CALFIT2$ID)){
    tmp <- CALFIT2[CALFIT2$ID == ID,
                   c("LOC_CLK","LOC_DOT",'prolific_id','screen_width','screen_height')]
    model <- lm(LOC_CLK~LOC_DOT, data=tmp)
    NUMTRIALS <- nrow(tmp)
    RSQ <- summary(model)$r.squared
    prolific_id <- tmp[1,3]
    #add to dataframe
    calibR <- rbind(calibR, cbind.data.frame(prolific_id,NUMTRIALS,RSQ))
}

# identify and remove participants with r2 < .9
## participants whose cal_fit < .9
calibR$FILTER <- calibR$RSQ < .90
# merge IDs and 
# adding to ID_X data-frame for later removal
cal_x <- append(cal_x, as.character(calibR[calibR$FILTER == TRUE, "prolific_id"]))
length(cal_x)
```

# Remove participants who did not pass calibration step
Obtain N for analysis (& power)
```{r}
# remove participants who failed calib check from current data-set
#all_dat_breaks <- filter(all_dat_breaks, !(prolific_id %in% cal_x))
all_dat_breaks <- filter(all_dat_breaks, !(prolific_id %in% cal_x))

# get final numbers
n <- count(all_dat_breaks, 'prolific_id')
length(n$prolific_id)

# recode IDs
all_dat_breaks$prolific_id <- as.factor(all_dat_breaks$prolific_id)
all_dat_breaks$ID <- as.character(as.numeric(all_dat_breaks$prolific_id))
```

# Use the data from the calibration step to rescale bisection responses to match screen scaling
```{r}
# isolate left and right - change should match across both but best to average jic
LEFTx <- dplyr::filter(CALFIT2, AXIS == 'x' & LOC_DOT <= 0)
RIGHTx <- dplyr::filter(CALFIT2, AXIS == 'x' & LOC_DOT >= 0)
# remove upper and lower y
LEFTx <- dplyr::filter(LEFTx, !LOC == 'uppery' & !LOC == 'lowery')
RIGHTx <- dplyr::filter(RIGHTx, !LOC == 'uppery' & !LOC == 'lowery')
# clean both, they are messy!
LEFTx <- LEFTx[, c(1,2,4:6,8,11)]
RIGHTx <- RIGHTx[, c(1,2,4:6,8,11)]

# cast!
L_cal <- dcast(LEFTx, prolific_id ~ LOC, value.var = "LOC_CLK")
L_dot <- dcast(LEFTx, prolific_id ~ LOC, value.var = "LOC_DOT")
# differences between points - to calculate rate of change
# do this for 480 and 192
L_cal$CAL_DIFF_480 <- L_cal$left480x - L_cal$midy
L_dot$DOT_DIFF_480 <- L_dot$left480x - L_dot$midy
L_cal$CAL_DIFF_192 <- L_cal$left192x - L_cal$midy
L_dot$DOT_DIFF_192 <- L_dot$left192x - L_dot$midy
# combine and calculate rate of change
L_rate <- merge(L_dot, L_cal, by = ('prolific_id'))
L_rate$rate480 <- L_rate$CAL_DIFF_480/L_rate$DOT_DIFF_480
L_rate$rate192 <- L_rate$CAL_DIFF_192/L_rate$DOT_DIFF_192

## repeat these steps for the right points, just to be sure
# cast!
R_cal <- dcast(RIGHTx, prolific_id ~ LOC, value.var = "LOC_CLK")
R_dot <- dcast(RIGHTx, prolific_id ~ LOC, value.var = "LOC_DOT")
# differences between points - to calculate rate of change
# do this for 480 and 192
R_cal$CAL_DIFF_480 <- R_cal$right480x - R_cal$midy
R_dot$DOT_DIFF_480 <- R_dot$right480x - R_dot$midy
R_cal$CAL_DIFF_192 <- R_cal$right192x - R_cal$midy
R_dot$DOT_DIFF_192 <- R_dot$right192x - R_dot$midy
# combine and calculate rate of change
R_rate <- merge(R_dot, R_cal, by = ('prolific_id'))
R_rate$rate480 <- R_rate$CAL_DIFF_480/R_rate$DOT_DIFF_480
R_rate$rate192 <- R_rate$CAL_DIFF_192/R_rate$DOT_DIFF_192

# apply this rate to the line bisection data - to scale bisection response
rate192 <- L_rate[, c(1,15)]
names(rate192)[2] <- 'L_rate'
rate192$R_rate <- R_rate$rate192
rate192$av_rate <- (rate192$L_rate+rate192$R_rate)/2

# merge
all_dat_breaks <- merge(all_dat_breaks, rate192, by = 'prolific_id')
n <- count(all_dat_breaks, prolific_id)
length(n$prolific_id)
```

# Saving!
Save all_dat and calib_dat dataframes
```{r}
compileFile = paste(aPath, 'LBT_compiled-data.csv', sep = '/')
write.csv(all_dat_breaks, compileFile, row.names = FALSE)
```


facet_wrap(~variable, scales = "free") +
# violin plots
geom_half_violin(data = pseudo %>% filter(variable == 'EWS'),
aes(x = 1, y = BIAS),
position = position_nudge(nudge2)) +
geom_half_violin(data = pseudo %>% filter(variable == 'EWB'),
aes(x = 1, y = BIAS),
position = position_nudge(nudge2)) +
geom_half_violin(data = pseudo %>% filter(variable == 'DBE'),
aes(x = 1, y = BIAS),
position = position_nudge(nudge2)) +
labs(x = '', y = 'Measurement') +
theme_classic() +
theme(axis.ticks.x = element_blank(),
axis.text.x = element_blank(),
axis.text.y = element_text(size = 11),
axis.title = element_text(size = 12),
strip.text.x = element_text(size = 12)) -> m_plot
m_plot <- m_plot +   geom_hline(data = data_hline,
aes(yintercept = hline), linetype = 'dashed', alpha = .5)
m_plot
View(pseudo_sum)
# plot the distribution of all data (and means?)
ggplot(data = pseudo, aes(group = variable)) +
geom_jitter(aes(x = 1, y = BIAS),
width = .05, shape = 21, size = 1.5, alpha = .8) +
facet_wrap(~variable, scales = "free") +
# violin plots
geom_half_violin(data = pseudo %>% filter(variable == 'EWS'),
aes(x = 1, y = BIAS),
position = position_nudge(nudge2)) +
geom_half_violin(data = pseudo %>% filter(variable == 'EWB'),
aes(x = 1, y = BIAS),
position = position_nudge(nudge2)) +
geom_half_violin(data = pseudo %>% filter(variable == 'DBE'),
aes(x = 1, y = BIAS),
position = position_nudge(nudge2)) +
# add summary stats
geom_point(data = pseudo_sum,
aes(x = 1, y = BIAS)) +
labs(x = '', y = 'Measurement') +
theme_classic() +
theme(axis.ticks.x = element_blank(),
axis.text.x = element_blank(),
axis.text.y = element_text(size = 11),
axis.title = element_text(size = 12),
strip.text.x = element_text(size = 12)) -> m_plot
m_plot
# plot the distribution of all data (and means?)
ggplot(data = pseudo, aes(group = variable)) +
geom_jitter(aes(x = 1, y = BIAS),
width = .05, shape = 21, size = 1.5, alpha = .8) +
facet_wrap(~variable, scales = "free") +
# violin plots
geom_half_violin(data = pseudo %>% filter(variable == 'EWS'),
aes(x = 1, y = BIAS),
position = position_nudge(nudge2)) +
geom_half_violin(data = pseudo %>% filter(variable == 'EWB'),
aes(x = 1, y = BIAS),
position = position_nudge(nudge2)) +
geom_half_violin(data = pseudo %>% filter(variable == 'DBE'),
aes(x = 1, y = BIAS),
position = position_nudge(nudge2)) +
# add summary stats
geom_point(data = pseudo_sum,
aes(x = 1, y = BIAS),
position = position_nudge(nudge2), size = 4) +
labs(x = '', y = 'Measurement') +
theme_classic() +
theme(axis.ticks.x = element_blank(),
axis.text.x = element_blank(),
axis.text.y = element_text(size = 11),
axis.title = element_text(size = 12),
strip.text.x = element_text(size = 12)) -> m_plot
m_plot
# plot the distribution of all data (and means?)
ggplot(data = pseudo, aes(group = variable)) +
geom_jitter(aes(x = 1, y = BIAS),
width = .05, shape = 21, size = 1.5, alpha = .8) +
facet_wrap(~variable, scales = "free") +
# violin plots
geom_half_violin(data = pseudo %>% filter(variable == 'EWS'),
aes(x = 1, y = BIAS),
position = position_nudge(nudge2)) +
geom_half_violin(data = pseudo %>% filter(variable == 'EWB'),
aes(x = 1, y = BIAS),
position = position_nudge(nudge2)) +
geom_half_violin(data = pseudo %>% filter(variable == 'DBE'),
aes(x = 1, y = BIAS),
position = position_nudge(nudge2)) +
# add summary stats
geom_point(data = pseudo_sum,
aes(x = 1, y = BIAS),
position = position_nudge(nudge2), size = 4) +
geom_errorbar(data = pseudo_sum,
aes(x = 1, ymin = BIAS-ci, ymax = BIAS+ci),
width = .05, size = .6)
# plot the distribution of all data (and means?)
ggplot(data = pseudo, aes(group = variable)) +
geom_jitter(aes(x = 1, y = BIAS),
width = .05, shape = 21, size = 1.5, alpha = .8) +
facet_wrap(~variable, scales = "free") +
# violin plots
geom_half_violin(data = pseudo %>% filter(variable == 'EWS'),
aes(x = 1, y = BIAS),
position = position_nudge(nudge2)) +
geom_half_violin(data = pseudo %>% filter(variable == 'EWB'),
aes(x = 1, y = BIAS),
position = position_nudge(nudge2)) +
geom_half_violin(data = pseudo %>% filter(variable == 'DBE'),
aes(x = 1, y = BIAS),
position = position_nudge(nudge2)) +
# add summary stats
geom_point(data = pseudo_sum,
aes(x = 1, y = BIAS),
position = position_nudge(nudge2), size = 4) +
geom_errorbar(data = pseudo_sum,
aes(x = 1, ymin = BIAS-ci, ymax = BIAS+ci),
width = .05, size = .6, position = position_nudge(nudge2)) +
labs(x = '', y = 'Measurement') +
theme_classic() +
theme(axis.ticks.x = element_blank(),
axis.text.x = element_blank(),
axis.text.y = element_text(size = 11),
axis.title = element_text(size = 12),
strip.text.x = element_text(size = 12)) -> m_plot
m_plot <- m_plot +   geom_hline(data = data_hline,
aes(yintercept = hline), linetype = 'dashed', alpha = .6)
m_plot
# plot the distribution of all data (and means?)
ggplot(data = pseudo, aes(group = variable)) +
geom_jitter(aes(x = 1, y = BIAS),
width = .05, shape = 21, size = 1.5, alpha = .8) +
facet_wrap(~variable, scales = "free") +
# violin plots
geom_half_violin(data = pseudo %>% filter(variable == 'EWS'),
aes(x = 1, y = BIAS),
position = position_nudge(nudge2)) +
geom_half_violin(data = pseudo %>% filter(variable == 'EWB'),
aes(x = 1, y = BIAS),
position = position_nudge(nudge2)) +
geom_half_violin(data = pseudo %>% filter(variable == 'DBE'),
aes(x = 1, y = BIAS),
position = position_nudge(nudge2)) +
# add summary stats
geom_point(data = pseudo_sum,
aes(x = 1, y = BIAS),
position = position_nudge(nudge2), size = 4) +
geom_errorbar(data = pseudo_sum,
aes(x = 1, ymin = BIAS-ci, ymax = BIAS+ci),
width = .03, size = .75, position = position_nudge(nudge2)) +
labs(x = '', y = 'Measurement') +
theme_classic() +
theme(axis.ticks.x = element_blank(),
axis.text.x = element_blank(),
axis.text.y = element_text(size = 11),
axis.title = element_text(size = 12),
strip.text.x = element_text(size = 12)) -> m_plot
m_plot <- m_plot +   geom_hline(data = data_hline,
aes(yintercept = hline), linetype = 'dashed', alpha = .6)
m_plot
# plot the distribution of all data (and means?)
ggplot(data = pseudo, aes(group = variable)) +
geom_jitter(aes(x = 1, y = BIAS),
width = .05, shape = 21, size = 1.5, alpha = .8) +
facet_wrap(~variable, scales = "free") +
# violin plots
geom_half_violin(data = pseudo %>% filter(variable == 'EWS'),
aes(x = 1, y = BIAS),
position = position_nudge(nudge2)) +
geom_half_violin(data = pseudo %>% filter(variable == 'EWB'),
aes(x = 1, y = BIAS),
position = position_nudge(nudge2)) +
geom_half_violin(data = pseudo %>% filter(variable == 'DBE'),
aes(x = 1, y = BIAS),
position = position_nudge(nudge2)) +
# add summary stats
geom_point(data = pseudo_sum,
aes(x = 1, y = BIAS),
position = position_nudge(nudge2), size = 4) +
geom_errorbar(data = pseudo_sum,
aes(x = 1, ymin = BIAS-ci, ymax = BIAS+ci),
width = .03, size = .1, position = position_nudge(nudge2)) +
labs(x = '', y = 'Measurement') +
theme_classic() +
theme(axis.ticks.x = element_blank(),
axis.text.x = element_blank(),
axis.text.y = element_text(size = 11),
axis.title = element_text(size = 12),
strip.text.x = element_text(size = 12)) -> m_plot
m_plot <- m_plot +   geom_hline(data = data_hline,
aes(yintercept = hline), linetype = 'dashed', alpha = .6)
m_plot
# plot the distribution of all data (and means?)
ggplot(data = pseudo, aes(group = variable)) +
geom_jitter(aes(x = 1, y = BIAS),
width = .05, shape = 21, size = 1.5, alpha = .8) +
facet_wrap(~variable, scales = "free") +
# violin plots
geom_half_violin(data = pseudo %>% filter(variable == 'EWS'),
aes(x = 1, y = BIAS),
position = position_nudge(nudge2)) +
geom_half_violin(data = pseudo %>% filter(variable == 'EWB'),
aes(x = 1, y = BIAS),
position = position_nudge(nudge2)) +
geom_half_violin(data = pseudo %>% filter(variable == 'DBE'),
aes(x = 1, y = BIAS),
position = position_nudge(nudge2)) +
# add summary stats
geom_point(data = pseudo_sum,
aes(x = 1, y = BIAS),
position = position_nudge(nudge2), size = 4) +
geom_errorbar(data = pseudo_sum,
aes(x = 1, ymin = BIAS-ci, ymax = BIAS+ci),
width = .03, size = 1, position = position_nudge(nudge2)) +
labs(x = '', y = 'Measurement') +
theme_classic() +
theme(axis.ticks.x = element_blank(),
axis.text.x = element_blank(),
axis.text.y = element_text(size = 11),
axis.title = element_text(size = 12),
strip.text.x = element_text(size = 12)) -> m_plot
m_plot <- m_plot +   geom_hline(data = data_hline,
aes(yintercept = hline), linetype = 'dashed', alpha = .6)
m_plot
# save plot
ggsave('Measurements.png', m_plot, device = NULL, path = aPath,
width = 9, height = 5, dpi = 600)
# plot the distribution of all data (and means?)
ggplot(data = pseudo, aes(group = variable)) +
geom_jitter(aes(x = 1, y = BIAS),
width = .05, shape = 21, size = 1.5, alpha = .8) +
facet_wrap(~variable, scales = "free") +
# violin plots
geom_half_violin(data = pseudo %>% filter(variable == 'EWS'),
aes(x = 1, y = BIAS),
position = position_nudge(nudge2)) +
geom_half_violin(data = pseudo %>% filter(variable == 'EWB'),
aes(x = 1, y = BIAS),
position = position_nudge(nudge2)) +
geom_half_violin(data = pseudo %>% filter(variable == 'DBE'),
aes(x = 1, y = BIAS),
position = position_nudge(nudge2)) +
# add summary stats
geom_point(data = pseudo_sum,
aes(x = 1, y = BIAS),
position = position_nudge(nudge2), size = 3.5) +
geom_errorbar(data = pseudo_sum,
aes(x = 1, ymin = BIAS-ci, ymax = BIAS+ci),
width = .03, size = 1, position = position_nudge(nudge2)) +
labs(x = '', y = 'Measurement') +
theme_classic() +
theme(axis.ticks.x = element_blank(),
axis.text.x = element_blank(),
axis.text.y = element_text(size = 11),
axis.title = element_text(size = 12),
strip.text.x = element_text(size = 12)) -> m_plot
m_plot <- m_plot +   geom_hline(data = data_hline,
aes(yintercept = hline), linetype = 'dashed', alpha = .6)
m_plot
# arrange with end_point_plot
m1_plot <- ggarrange(end_points_plot, m_plot,
nrow = 1, ncol = 2,
labels = c('a.','b.'))
m1_plot
# arrange with end_point_plot
m1_plot <- ggarrange(end_points_plot, m_plot,
nrow = 1, ncol = 2,
labels = c('a.','b.'),
widths = c(.5,1))
m1_plot
# arrange with end_point_plot
m1_plot <- ggarrange(end_points_plot, m_plot,
nrow = 1,
labels = c('a.','b.'))
m1_plot
# arrange with end_point_plot
m1_plot <- ggarrange(end_points_plot, m_plot,
nrow = 1, ncol = 2,
labels = c('a.','b.'),
widths = c(.5,1),
layout(rbind(c(1,2),
c(NA,2))))
# arrange with end_point_plot
m1_plot <- ggarrange(end_points_plot, m_plot,
nrow = 1, ncol = 2,
labels = c('a.','b.'),
widths = c(.5,1),
layout_matrix = (rbind(c(1,2),
c(NA,2))))
m1_plot
# arrange with end_point_plot
m1_plot <- ggarrange(end_points_plot, m_plot,
nrow = 1, ncol = 2,
labels = c('a.','b.'),
widths = c(.5,1),
layout_matrix = (cbind(c(1,NA),
c(2,2))))
m1_plot
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(reshape2)
library(ggpol)
library(ggpubr)
library(Rmisc)
library(gghalves)
library(RColorBrewer)
library(gghalves)
aPath <- '/Users/au706616/Documents/Experiments/PIPTOT/analysis/'
fileName <- 'LBT_compiled-data.csv'
all_dat <- read.csv(file.path(aPath,fileName))
## First, code bisection error
#all_dat$bisect_x_scaled <- all_dat$bisect_x/all_dat$av_rate
# before calculating bisection error check bisect_x and calib_loc_mid make sense
#bisect_check <- aggregate(bisect_x_scaled ~ prolific_id*left_mm*right_mm*calib_loc_midy_x,
#                         mean, data = all_dat)
# yep that seems to make sense, now convert and do the same
all_dat$bisect_error <- all_dat$bisect_x - all_dat$calib_loc_midy_x
# then scale the error by coordinate change rate calculated in previous step
all_dat$bisect_error_scaled <- all_dat$bisect_error/all_dat$av_rate
all_dat$bisect_error_scaled <- all_dat$bisect_error_scaled/all_dat$pix_permm #transfer to mm
bisect_check <- aggregate(bisect_error_scaled ~ prolific_id*left_mm*right_mm,
mean, data = all_dat)
bisect_check$offset <- (bisect_check$left_mm + bisect_check$right_mm)/2
# yes this step makes sense for most people, plot it just incase
all_plot <- ggplot(bisect_check, aes(group = as.factor(offset), colour = as.factor(offset))) +
geom_point(aes(bisect_error_scaled, y = 0)) +
xlim(-75,75) +
theme_bw() +
facet_wrap(~prolific_id)
all_plot
# some more filtering
# remove trials with response > 3000ms
all_dat <- dplyr::filter(all_dat, response_time < 3000)
# identify any participants with too few trials, less than 32 per condition
trials <- aggregate(bisect_error ~ prolific_id*pip*block, length, data = all_dat)
id_x <- trials$prolific_id[trials$bisect_error < 32]
# check all participants have levels of both factors (block and tone)
nblock <- aggregate(bisect_error ~ block*prolific_id, length, data = all_dat)
nblock <- nblock %>%
group_by(prolific_id) %>%
tally()
ntone <- aggregate(bisect_error ~ pip*prolific_id, length, data = all_dat)
ntone <- ntone %>%
group_by(prolific_id) %>%
tally()
# and remove those that don't
id_x <- append(id_x, nblock$prolific_id[nblock$n < 2])
id_x <- append(id_x, ntone$prolific_id[nblock$n < 2])
all_dat <- filter(all_dat, !(prolific_id %in% id_x))
n <- count(all_dat, 'prolific_id')
length(n$prolific_id)
# recode ID
all_dat$prolific_id <- as.factor(all_dat$prolific_id)
all_dat$ID <- as.character(as.numeric(all_dat$prolific_id))
all_dat <- all_dat[order(all_dat$ID), ]
rownames(all_dat) <- NULL
View(all_dat)
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(reshape2)
library(glmmTMB)
library(ggplot2)
library(plyr)
library(lme4)
dPath <- '/Users/au706616/Documents/Experiments/PIPTOT/LBTraw'
aPath <- '/Users/au706616/Documents/Experiments/PIPTOT/analysis/'
datname <- 'LBTraw_final.csv'
dat2name <- 'LBTraw_final2.csv'
qualname <- 'QUALraw_final2.csv'
# load raw and qual data
bisectData <- read.csv(file.path(dPath,datname))
bisect2Data <- read.csv(file.path(dPath,dat2name)) #another data set with extra 85 participants (due to data-loss)
qualData <- read.csv(file.path(dPath,qualname))
# flag first and second recruitment rounds
bisectData$recruit <- 1
bisect2Data$recruit <- 2
# rbind bisect data-sets
bisectData <- rbind(bisectData, bisect2Data)
# first get an idea of all participants (prolific IDs)
nres <- aggregate(acc~prolific_id, length, data=bisectData)
length(nres$prolific_id)
# n particiants removed who failed audio check/too few trials
nAudio <- dplyr::filter(nres, acc < 200)
# id_x <- nAudio$prolific_id #identifying participants to be removed
# count void trials - identify excessive
void <- dplyr::filter(bisectData, void_trial == 1)
nVoid <- aggregate(void_trial~prolific_id, length, data=void)
# narrow down data-frame to relevant columns only - putting important first
dat <- bisectData[, c(224,6,11,12,26,289,211,212,274,275,214,36,37,46,89,164,165,206,207,
208,216:218,222,223,225,228,229,237,251,352,356,319,321,322,386,388,
131,385,389)]
# data for calibration check, seperate from main df
calib_dat <- bisectData[, c(224,17:34,172:189,281,287,208)]
## Qualitative data
# Load and merge with qualitative data
## Qualitative data
qualData <- read.csv(file.path(dPath,qualname))
# first, some renaming and reorganising of the qual data
names(qualData)[1] <- 'consent'
names(qualData)[2] <- 'prolific_id'
names(qualData)[3] <- 'gender'
names(qualData)[4] <- 'age'
# split off EHI
EHI <- qualData[, c(2,6:15)]
qualData <- qualData[, c(2,1,3,4)]
# merge with bisection data using jatos IDs to obtain prolific id, to merge data-frames
dat <- merge(qualData, dat, by = 'prolific_id')
calib_dat <- merge(qualData, calib_dat, by = 'prolific_id')
# remove unecessary columns from calib10 - to match other calibration
calib_dat <- calib_dat[, -c(2,3,4)]
# do the same as above for the first 10 participants (collected seperately)
# then combine their data
dat10name <- 'LBTraw_first10.csv'
qual10name <- 'QUALraw_first10.csv'
# first only load the raw data because demographic is a little useless at this stage
bisect10Data <- read.csv(file.path(dPath,dat10name))
bisect10Data$recruit <- 1
# same filtering as above
# first get an idea of all participants (prolific IDs)
nres10 <- aggregate(acc~jatosStudyResultId, length, data=bisect10Data)
length(nres10$jatosStudyResultId)
# n particiants removed who failed audio check/too few trials
nAudio10 <- dplyr::filter(nres10, acc < 200)
#id_x10 <- nAudio10$jatosStudyResultId #identifying participants to be removed
# count void trials
void10 <- dplyr::filter(bisect10Data, void_trial == 1)
# narrow down data-frame for correct columns only
dat10 <- bisect10Data[, c(6,11,12,26,271,201,202,256,257,204,36,37,45,81,154,155,196,197,
198,206:208,212,213,215,218,219,224,237,326,330,294,296,297,
359,361,123,358,362)]
calib10 <- bisect10Data[, c(17:34,162:179,263,269,198)]
## Qualitative data
qual10Data <- read.csv(file.path(dPath,qual10name))
# flag PIDs with no code & no data
nPID <- c('611e1eee7989eadcee23045c', '6025df3ed83eed206142329a', '6130d846086f43ecd225d128')
# qualitative data
# first, some renaming and reorganising of the qual data
names(qual10Data)[1] <- 'consent'
names(qual10Data)[2] <- 'prolific_id'
names(qual10Data)[3] <- 'gender'
names(qual10Data)[4] <- 'age'
# remove no code PIDs from quantitative
qual10Data <- filter(qual10Data, !(prolific_id %in% nPID))
# split off EHI
EHI10 <- qual10Data[, c(2,6:15)]
qual10Data <- qual10Data[, c(2,1,3,4,16)]
# merge with bisection data using jatos IDs to obtain prolific id, to merge data-frames
dat10 <- merge(qual10Data, dat10, by = 'jatosStudyResultId')
calib10 <- merge(qual10Data, calib10, by = 'jatosStudyResultId')
# remove unecessary columns from calib10 - to match other calibration
calib10 <- calib10[, -c(3,4,5)]
# Bind the smaller initial data set with the main data set to get final numbers
all_dat <- rbind(dat, dat10)
# number before calibration step
nvalid <- count(all_dat, 'prolific_id')
length(nvalid$prolific_id)
# save entire data-frame (before quality checks)
wholeFile = paste(aPath, 'LBT_all-compiled-data.csv', sep = '/')
write.csv(all_dat, wholeFile, row.names = FALSE)
# filter trials so audio = passed, this removes audio step and filters participants who failed
all_dat <- dplyr::filter(all_dat, audio_passed == 1)
# then remove void trials
all_dat <- dplyr::filter(all_dat, void_trial == 0 & practice == 0)
# number of trials for each participant with void and practice removed
ndat <- aggregate(bisect_x~prolific_id, length, data=bisectData)
ndat <- ndat[order(ndat$prolific_id) ,] # order by prolific id for easy identification
# this is the actual number of participants recruited
length(ndat$prolific_id)
# count n participants from each round
nRec1 <- all_dat %>%
filter(recruit == 1) %>%
count('prolific_id')
nRec2 <- all_dat %>%
filter(recruit == 2) %>%
count('prolific_id')
# define some key criteria
# extract variables of interest for quality checks
# first response time to line in ms
all_dat$response_time <- all_dat$time_cursor_locs - all_dat$time_line
rt <- aggregate(response_time ~ prolific_id, mean, data = all_dat) # check it makes sense
# then length of break (in seconds)
all_dat$break_time <- (all_dat$time_break_time_stamp - all_dat$time_block_one_end)/1000
bt <- aggregate(break_time ~ prolific_id, mean, data = all_dat) # check it makes sense
# code conditions of interest - block and tone (pip)
all_dat$block <- ifelse(is.na(all_dat$count_block_2_sequence), 1, 2) #identifying block
all_dat$pip <- ifelse(all_dat$sound == 'blank', 0, 1) #if tone == 1
# PARTICIPANT REMOVAL
# there are participants that, for some reason trials have been doubled, remove those
# first order by line response count
all_dat <- all_dat[order(all_dat$count_line_mouse_response) ,]
# then prolific id
all_dat <- all_dat[order(all_dat$prolific_id) ,]
# then remove repeat trials
all_dat <- all_dat %>%
group_by(prolific_id) %>%
distinct(count_line_mouse_response, .keep_all = TRUE)
# remove participants with breaks > 5 minutes
id_x <- bt$prolific_id[bt$break_time > 301] #this step removes 63 participants!
# final audio check, correct?
finalAudio <- bisectData[bisectData$response_audio_kbd_final == 7 ,]
finalAudio <- finalAudio[, c(225,237)]
length(finalAudio$queryParams_PROLIFIC_PID)
# remove participants with long breaks from full data set
# but keep data frame that reserves these participants, because that is a lot
# DON'T RUN this step yet - need confirmation
all_dat_breaks <- filter(all_dat, !(prolific_id %in% id_x))
# n remaining participants
nvalid <- aggregate(bisect_x~prolific_id, length, data=all_dat_breaks)
length(nvalid$prolific_id)
View(all_dat_breaks)

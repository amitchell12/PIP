theme_classic() +
theme(legend.position = 'none')
f6
View(all_coeff)
# all coeff, get a data-frame with all phs and conditions - detect and pain
all_coeff <- merge(detect_coeff, pain_coeff, by = c('subject', 'baseline','(Intercept)'))
# rename
names(all_coeff)[names(all_coeff) == 'phs.x'] <- 'phs_detect_n'
names(all_coeff)[names(all_coeff) == 'phs.y'] <- 'phs_pain_n'
# create column that codes no phs, just one phs or both phs
all_coeff$phs_both <- rowSums(all_coeff[c(5,7)])
# create column that codes no phs, phs detect or phs pain, or both
for (l in 1:length(all_coeff$subject)){
if (isTRUE(all_coeff$phs_detect[l] == 1 & all_coeff$phs_pain[l] == 0)){
all_coeff$phs_code[l] = 1
} else if (isTRUE(all_coeff$phs_detect[l] == 0 & all_coeff$phs_pain[l] == 1)) {
all_coeff$phs_code[l] = 2
} else if (isTRUE(all_coeff$phs_detect[l] == 1 & all_coeff$phs_pain[l] == 1)) {
all_coeff$phs_code[l] = 3
} else {
all_coeff$phs_code[l] = 0
}
}
# summary statistics
allB_mean <- aggregate(baseline~phs_code, mean, data = all_coeff)
allB_median <- aggregate(baseline~phs_code, median, data = all_coeff)
allB_sd <- aggregate(baseline~phs_code, sd, data = all_coeff)
allB_sderr <- allB_sd$baseline/sqrt(N)# number of participants
allB_ci <- aggregate(baseline~phs_code, CI, data = all_coeff)
# data frame
allB_stats <- data.frame(phs_code = allB_mean$phs_code,
mean = allB_mean$baseline, median = allB_median$baseline,
sd = allB_sd$baseline, stderr = allB_sderr,
allB_ci$baseline)
# rename CI labels
names(allB_stats)[names(allB_stats) == 'upper'] <- 'ci_upper'
names(allB_stats)[names(allB_stats) == 'mean.1'] <- 'ci_mean'
names(allB_stats)[names(allB_stats) == 'lower'] <- 'ci_lower'
# calculate ci
allB_stats$ci <- allB_stats$ci_upper - allB_stats$ci_lower
# figure
blues <- brewer.pal(8, "Blues")
all_coeff$xj <- jitter(all_coeff$phs_detect, amount = .1)
# plot coefficients - vs. phs pain
f6 <- ggplot(data = all_coeff,
mapping = aes(x = phs_code, y = baseline, fill = as.factor(phs_code))) +
geom_point(aes(x = xj), shape = 21, size = 2, alpha = .6) +
# Add rainclouds
geom_half_violin(
data = all_coeff %>%
filter(phs_code == 0), aes(x = phs_code, y = baseline),
position = position_nudge(x = nudge1), side = "r", fill = blues[2], alpha = .6
) +
geom_half_violin(
data = all_coeff %>%
filter(phs_code == 1),aes(x = phs_code, y = baseline),
position = position_nudge(x = nudge1), side = "r", fill = blues[4], alpha = .6
) +
geom_half_violin(
data = all_coeff %>%
filter(phs_code == 2),aes(x = phs_code, y = baseline),
position = position_nudge(x = nudge1), side = "r", fill = blues[6], alpha = .6
) +
geom_half_violin(
data = all_coeff %>%
filter(phs_code == 3),aes(x = phs_code, y = baseline),
position = position_nudge(x = nudge1), side = "r", fill = blues[8], alpha = .6
) +
# means & errors bars
geom_pointrange(
data = allB_stats %>%
filter(phs_code == 0),
aes(x = phs_code, y = ci_mean, ymin = ci_lower, ymax = ci_upper),
position = position_nudge(nudge2)) +
geom_pointrange(
data = allB_stats %>%
filter(phs_code == 1),
aes(x = phs_code, y = ci_mean, ymin = ci_lower, ymax = ci_upper),
position = position_nudge(nudge2)) +
geom_pointrange(
data = allB_stats %>%
filter(phs_code == 2),
aes(x = phs_code, y = ci_mean, ymin = ci_lower, ymax = ci_upper),
position = position_nudge(nudge2)) +
geom_pointrange(
data = allB_stats %>%
filter(phs_code == 3),
aes(x = phs_code, y = ci_mean, ymin = ci_lower, ymax = ci_upper),
position = position_nudge(nudge2)) +
# add zero line
geom_hline(yintercept = 0, alpha = .5) +
# Define additional settings
scale_x_continuous(breaks=c(0.1,1.1,2.1,3.1),
labels=c("None", "Innocuous","Noxious","Both"), ) +
scale_fill_manual(labels = c("None", "Innocuous","Noxious","Both"),
values=c(blues[2],blues[4],blues[6],blues[8])) +
labs(title = "", y = "Beta coefficient",
x = "Paradoxical Heat Sensations") +
ggtitle('Contrast sensitivity and PHS') +
theme_classic() +
theme(legend.position = 'none')
f6
# Prepare the data
# select specific trials for analysis
df2 <- tsl2 %>%
filter(task == "tsl2" & trials_to_keep == 1)
# calculating the innocuous cold range for each trial
df_detect2 <- df2 %>%
filter(instruction == 'detect')
df_pain2 <- df2 %>%
filter(instruction == 'pain')
diff2 <- df_detect2$threshold - df_pain2$threshold
df2 <- data.frame(subject = df_detect2$exp_id, baseline = df_detect2$baseline,
trial = df_detect2$trial, phs = df_detect2$phs,
measure = rep("detect-pain", nrow(df_detect2)), difference = diff2)
# grouping by baseline- take the standardised values
df_32 <- df2 %>%
filter(baseline == 32) %>%
dplyr::rename(icr32 = difference,
phs32 = phs)
df_38 <- df2 %>%
filter(baseline == 38) %>%
dplyr::rename(icr38 = difference,
phs38 = phs)
df_44 <- df2 %>%
filter(baseline == 44) %>%
dplyr::rename(icr44 = difference,
phs44 = phs)
# merge
df_lcm <- merge(df_32, df_38, by = c('subject','trial','measure'))
df_lcm <- merge(df_lcm, df_44, by = c('subject','trial','measure'))
# select relevant columns
df_lcm <- df_lcm[, c(1:3,5,6,8,9,11,12)]
# as factors
df_lcm$phs32 <- as.factor(df_lcm$phs32)
df_lcm$phs38 <- as.factor(df_lcm$phs38)
df_lcm$phs44 <- as.factor(df_lcm$phs44)
# path analysis to investigate effect of baseline temperatures (32, 38, 44) on the innocuous cold range
# model - this is currently without phs
# intercept coefficients always 1
# slope coefficients increase by 1 with each predictor
# allow intercept and slope to vary but constrain residuals
baseline.model <- '
i =~ 1*icr32 + 1*icr38 + 1*icr44
s =~ 0*icr32 + 1*icr38 + 2*icr44
'
# run model
baseline.fit <- growth(baseline.model, data = df_lcm, estimator = 'MLM')
summary(baseline.fit)
# different model
phs_var.model2 <- '
i =~ 1*icr32 + 1*icr38 + 1*icr44
s =~ 0*icr32 + 1*icr38 + 2*icr44
icr32 ~ phs32
icr38 ~ phs38
icr44 ~ phs44
'
# and a more different model
phs_var.model3 <- '
i =~ 1*phs32 + 1*phs38 + 1*phs44
s =~ 0*phs32 + 1*phs38 + 2*phs44
phs32 ~ icr32
phs38 ~ icr38
phs44 ~ icr44
'
# run model
phs2.fit <- growth(phs_var.model2, data = df_lcm, estimator = 'MLR')
summary(phs2.fit, fit.measures = TRUE, standardized = TRUE)
View(df_lcm)
# path analysis to investigate effect of baseline temperatures (32, 38, 44) on the innocuous cold range
# model - this is currently without phs
# intercept coefficients always 1
# slope coefficients increase by 1 with each predictor
# allow intercept and slope to vary but constrain residuals
baseline.model <- '
i =~ 1*icr32 + 1*icr38 + 1*icr44
s =~ 0*icr32 + 1*icr38 + 2*icr44
'
# run model
baseline.fit <- growth(baseline.model, data = df_lcm, estimator = 'MLM')
summary(baseline.fit, fit.measures = TRUE, standardized = TRUE)
View(df_pain)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)  # data manipulation
library(rcompanion)
library(lme4)
library(lmerTest)
library(gghalves)
library(ggpubr)
library(wesanderson)
library(Rmisc)
library(ROCR)
library(caret)
library(groupdata2)
library(boot)
# simple model with only phs and baseline
# more complex model with phs, baseline and thermal thresholds (model of interest)
model.dp2 <- lme4::glmer(phs~baseline + detectz_threshold + avg_painz_threshold + (1|exp_id),
data = df_dp,
family = 'binomial') #, weights = train_dp$weights)
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)  # data manipulation
library(rcompanion)
library(lme4)
library(lmerTest)
library(gghalves)
library(ggpubr)
library(wesanderson)
library(Rmisc)
library(ROCR)
library(caret)
library(groupdata2)
library(boot)
Dpath <- '/Users/au706616/Documents/Experiments/PHS-SKULDNET/'
filename <- "allsub_tsl2_208.csv"
tsl2 <- read.csv(file.path(Dpath,filename))
# first, correct all pain thresholds < 0 to 0
N = 208
df2 <- tsl2 %>%
filter(task == "tsl2" & trials_to_keep == 1)
df2$threshold[df2$threshold < 0] = 0
# create average threshold - not needed here
avg_threshold <- aggregate(threshold~exp_id*baseline*instruction, mean, data = df2)
names(avg_threshold)[4] <- 'avg_threshold'
df2 <- merge(df2, avg_threshold, by = c('exp_id','baseline','instruction'), all.x = TRUE)
# split up pain and detection data sets - is instruction*threshold interaction on phs purely driven by instruction?
df_pain <- df2 %>%
filter(instruction == 'pain')
df_detect <- df2 %>%
filter(instruction == 'detect')
# change phs to a factor
df_pain$phs <- as.factor(df_pain$phs)
df_detect$phs <- as.factor(df_detect$phs)
# add pain threshold to detect data
#pain_thresh <- df_pain[, c(1,2,4,7,8)]
pain_thresh <- df_pain[, c(1,2,10,11,16)]
df_dp <- merge(df_detect, pain_thresh, by = c('exp_id', 'trial', 'baseline'))
# rename thresholds
df_dp<- df_dp %>%
dplyr::rename(
detect_threshold = threshold.x,
pain_threshold = threshold.y,
avg_detect_threshold = avg_threshold.x,
avg_pain_threshold = avg_threshold.y
)
df_dp$phs <- as.factor(df_dp$phs)
df_dp$baseline <- as.factor(df_dp$baseline)
df_dp$exp_id <- as.numeric(as.character(df_dp$exp_id))
# remove unnecessary data
df_dp <- df_dp[, c(1:3,11,14,17,18)]
# also normalise in original dataset
df_dp$detectz_threshold <- (df_dp$detect_threshold -
mean(df_dp$detect_threshold))/sd(df_dp$detect_threshold)
df_dp$painz_threshold <- (df_dp$pain_threshold -
mean(df_dp$pain_threshold))/sd(df_dp$pain_threshold)
df_dp$avg_painz_threshold <- (df_dp$avg_pain_threshold -
mean(df_dp$avg_pain_threshold))/sd(df_dp$avg_pain_threshold)
# density plots
ggplot(df_dp) +
geom_density(aes(detect_threshold), colour = 'red') +
geom_density(aes(detectz_threshold))
ggplot(df_dp) +
geom_density(aes(avg_pain_threshold), colour = 'red') +
geom_density(aes(avg_painz_threshold))
ggplot(df_dp) +
geom_density(aes(avg_pain_threshold), colour = 'red') +
geom_density(aes(avg_painz_threshold))
# simple model with only phs and baseline
# more complex model with phs, baseline and thermal thresholds (model of interest)
model.dp1 <- lme4::glmer(phs~baseline + (1|exp_id),
data = df_dp,
family = 'binomial') #, weights = train_dp$weights)
summary(model.dp1)
# calculating odds ratios
# need to find a way of getting CIs from this
or.dp1 <- exp(coef(summary(model.dp1)))
or.dp1
# simple model with only phs and baseline
# more complex model with phs, baseline and thermal thresholds (model of interest)
model.dp2 <- lme4::glmer(phs~baseline + detectz_threshold + avg_painz_threshold + (1|exp_id),
data = df_dp,
family = 'binomial') #, weights = train_dp$weights)
summary(model.dp2)
# calculating odds ratios
# need to find a way of getting CIs from this
or.dp2 <- exp(coef(summary(model.dp2)))
or.dp2
# simple model with only phs and baseline
# more complex model with phs, baseline and thermal thresholds (model of interest)
model.dp2 <- lme4::glmer(phs~as.ordered(baseline)
+ detectz_threshold + avg_painz_threshold + (1|exp_id),
data = df_dp,
family = 'binomial') #, weights = train_dp$weights)
summary(model.dp2)
# calculating odds ratios
# need to find a way of getting CIs from this
or.dp2 <- exp(coef(summary(model.dp2)))
or.dp2
# simple model with only phs and baseline
# more complex model with phs, baseline and thermal thresholds (model of interest)
model.dp1 <- lme4::glmer(phs~as.ordered(baseline) + (1|exp_id),
data = df_dp,
family = 'binomial') #, weights = train_dp$weights)
summary(model.dp1)
# calculating odds ratios
# need to find a way of getting CIs from this
or.dp1 <- exp(coef(summary(model.dp1)))
or.dp1
# simple model with only phs and baseline
# more complex model with phs, baseline and thermal thresholds (model of interest)
model.dp2 <- lme4::glmer(phs~as.ordered(baseline)
+ avg_painz_threshold + (1|exp_id),
data = df_dp,
family = 'binomial') #, weights = train_dp$weights)
summary(model.dp2)
# simple model with only phs and baseline
# more complex model with phs, baseline and thermal thresholds (model of interest)
model.dp2 <- lme4::glmer(phs~as.ordered(baseline)
+ detectz_threshold + avg_painz_threshold + (1|exp_id),
data = df_dp,
family = 'binomial') #, weights = train_dp$weights)
summary(model.dp2)
# calculating odds ratios
# need to find a way of getting CIs from this
or.dp2 <- exp(coef(summary(model.dp2)))
or.dp2
df_dp$exp_id <- as.factor(df_dp$exp_id)
set.seed(4123) # making this reproducible
resamples <- group_vfold_cv(df_dp, group = 'exp_id', v = 4)
library(rsample)
df_dp$exp_id <- as.factor(df_dp$exp_id)
set.seed(4123) # making this reproducible
resamples <- group_vfold_cv(df_dp, group = 'exp_id', v = 4)
train <- lapply(resamples$splits, training)
test <- lapply(resamples$splits, testing)
# pick one
train_dp <- train[[1]]
test_dp <- test[[1]]
# fold the dataset to make sure that id is equally represented
# calculate 80% of exp_id
#P <- N*.8
#df_dp <- fold(df_dp, k = round(P, 0), id_col = 'exp_id', method = 'greedy')
# then split by fold
#train_dp <- df_dp[df_dp$.folds == '1' ,]
#test_dp <- df_dp[df_dp$.folds == '2', ]
# standardise threshold values independently in each data-set
# normalise pain and detection thresholds by changing to logarithmic
train_dp$detectz_threshold <- (train_dp$detect_threshold -
mean(train_dp$detect_threshold))/sd(train_dp$detect_threshold)
train_dp$avg_painz_threshold <- (train_dp$avg_pain_threshold -
mean(train_dp$avg_pain_threshold))/sd(train_dp$avg_pain_threshold)
test_dp$detectz_threshold <- (test_dp$detect_threshold -
mean(test_dp$detect_threshold))/sd(test_dp$detect_threshold)
test_dp$avg_painz_threshold <- (test_dp$avg_pain_threshold -
mean(test_dp$avg_pain_threshold))/sd(test_dp$avg_pain_threshold)
# define training control
model.dp3 <- lme4::glmer(phs~baseline + (1|exp_id),
data = train_dp,
family = 'binomial') #, weights = train_dp$weights)
summary(model.dp3)
# ROC into test data
pred_resp_dp3 <- predict(model.dp3, test_dp, type="response", re.form = ~0)
pr_dp3 <- prediction(as.numeric(pred_resp_dp3), test_dp$phs)
prf_dp3 <- performance(pr_dp3, measure = "tpr", x.measure = "fpr")
auc <- performance(pr_dp3, "auc")
auc_dp3 <- as.numeric(auc@y.values)
# plotting
plot(prf_dp3, colorize = TRUE, lwd=2) +
# performance metrics TPR: True Positive Ratio FPR: False Positive Ratio
abline(0, 1, col = "black") +
legend("bottomright", paste(round(auc_dp3, 2)),
col = "black", pch = c(3))
# define training control
model.dp4 <- lme4::glmer(phs~baseline + detectz_threshold + avg_painz_threshold + (1|exp_id),
data = train_dp,
family = 'binomial') #, weights = train_dp$weights)
summary(model.dp4)
# ROC into test data
pred_resp_dp4 <- predict(model.dp4, test_dp, type="response", reform = ~0)
# define training control
model.dp3 <- lme4::glmer(phs~baseline + (1|exp_id),
data = train_dp,
family = 'binomial') #, weights = train_dp$weights)
summary(model.dp3)
# ROC into test data
pred_resp_dp3 <- predict(model.dp3, test_dp, type="response", re.form = ~0)
pr_dp3 <- prediction(as.numeric(pred_resp_dp3), test_dp$phs)
prf_dp3 <- performance(pr_dp3, measure = "tpr", x.measure = "fpr")
auc <- performance(pr_dp3, "auc")
auc_dp3 <- as.numeric(auc@y.values)
# plotting
plot(prf_dp3, colorize = TRUE, lwd=2) +
# performance metrics TPR: True Positive Ratio FPR: False Positive Ratio
abline(0, 1, col = "black") +
legend("bottomright", paste(round(auc_dp3, 2)),
col = "black", pch = c(3))
# ROC into test data
pred_resp_dp3 <- predict(model.dp3, test_dp, type="response", allow.new.levels = TRUE)
pr_dp3 <- prediction(as.numeric(pred_resp_dp3), test_dp$phs)
prf_dp3 <- performance(pr_dp3, measure = "tpr", x.measure = "fpr")
auc <- performance(pr_dp3, "auc")
auc_dp3 <- as.numeric(auc@y.values)
# plotting
plot(prf_dp3, colorize = TRUE, lwd=2) +
# performance metrics TPR: True Positive Ratio FPR: False Positive Ratio
abline(0, 1, col = "black") +
legend("bottomright", paste(round(auc_dp3, 2)),
col = "black", pch = c(3))
# define training control
model.dp4 <- lme4::glmer(phs~baseline + detectz_threshold + avg_painz_threshold + (1|exp_id),
data = train_dp,
family = 'binomial') #, weights = train_dp$weights)
summary(model.dp4)
# ROC into test data
pred_resp_dp4 <- predict(model.dp4, test_dp, type="response", re.form = ~0)
pr_dp4 <- prediction(as.numeric(pred_resp_dp4), test_dp$phs)
prf_dp4 <- performance(pr_dp4, measure = "tpr", x.measure = "fpr")
auc <- performance(pr_dp4, "auc")
auc_dp4 <- as.numeric(auc@y.values)
# plotting ROC
plot(prf_dp4, colorize = TRUE, lwd=2) +
# performance metrics TPR: True Positive Ratio FPR: False Positive Ratio
abline(0, 1, col = "black") +
legend("bottomright", paste(round(auc_dp4, 2)),
col = "black", pch = 3)
df_dp$exp_id <- as.factor(df_dp$exp_id)
set.seed(4123) # making this reproducible
resamples <- group_vfold_cv(df_dp, group = 'exp_id', v = 4)
train <- lapply(resamples$splits, training)
test <- lapply(resamples$splits, testing)
# pick one
train_dp <- train[[1]]
test_dp <- test[[1]]
# fold the dataset to make sure that id is equally represented
# calculate 80% of exp_id
#P <- N*.8
#df_dp <- fold(df_dp, k = round(P, 0), id_col = 'exp_id', method = 'greedy')
# then split by fold
#train_dp <- df_dp[df_dp$.folds == '1' ,]
#test_dp <- df_dp[df_dp$.folds == '2', ]
# standardise threshold values independently in each data-set
# normalise pain and detection thresholds by changing to logarithmic
train_dp$detectz_threshold <- (train_dp$detect_threshold -
mean(train_dp$detect_threshold))/sd(train_dp$detect_threshold)
train_dp$avg_painz_threshold <- (train_dp$avg_pain_threshold -
mean(train_dp$avg_pain_threshold))/sd(train_dp$avg_pain_threshold)
test_dp$detectz_threshold <- (test_dp$detect_threshold -
mean(test_dp$detect_threshold))/sd(test_dp$detect_threshold)
test_dp$avg_painz_threshold <- (test_dp$avg_pain_threshold -
mean(test_dp$avg_pain_threshold))/sd(test_dp$avg_pain_threshold)
View(test)
View(train)
View(test_dp)
knitr::opts_chunk$set(echo = TRUE)
# first only load the raw data because demographic is a little useless at this stage
bisectData <- read.csv(file.path(dPath,datname))
dPath <- '/Users/au706616/Documents/Experiments/PIPTOT/LBTraw'
aPath <- '/Users/au706616/Documents/Experiments/PIPTOT/analysis'
datname <- 'LBTraw_first10.csv'
qualname <- 'QUALraw_first10.csv'
# first only load the raw data because demographic is a little useless at this stage
bisectData <- read.csv(file.path(dPath,datname))
View(bisectData)
# first, number of trials for each participant
ntrials <- aggregate(acc~date_starttime, length, data=bisectData)
View(ntrials)
# number of trials for each participant
ntrials <- aggregate(acc~datetime, length, data=bisectData)
View(ntrials)
# number of trials for each participant
ntrials <- aggregate(acc~jatosStudyResultId, length, data=bisectData)
View(ntrials)
# filter trials so audio = passed, this removes audio step and filters participants who failed
# number of trials for each participant
ntrials <- aggregate(acc~jatosStudyResultId, length, data=bisectData)
# filter trials so audio = passed, this removes audio step and filters participants who failed
bisectData <- filter(bisectData, audio_passed == 1)
library(tidyverse)
# filter trials so audio = passed, this removes audio step and filters participants who failed
bisectData <- dplyr::filter(bisectData, audio_passed == 1)
View(bisectData)
# number of trials for each participant
ntrials <- aggregate(acc~jatosStudyResultId, length, data=bisectData)
View(ntrials)
# check sounds have been recorded
bisectMean <- aggregate(bisect_x~sound+jatosStudyResultId, mean, data = bisectData)
View(bisectMean)
# check sounds have been recorded
bisectMean <- aggregate(bisect_x~sound+jatosStudyResultId, length, data = bisectData)
# then remove void trials
bisectData <- dplyr::filter(bisectData, void == 0)
# then remove void trials
bisectData <- dplyr::filter(bisectData, void_trial == 0)
# number of trials for each participant
ntrials <- aggregate(acc~jatosStudyResultId, length, data=bisectData)
View(ntrials)
# first only load the raw data because demographic is a little useless at this stage
bisectData <- read.csv(file.path(dPath,datname))
# filter trials so audio = passed, this removes audio step and filters participants who failed
bisectData <- dplyr::filter(bisectData, audio_passed == 1)
# then remove void trials
bisectData <- dplyr::filter(bisectData, void_trial == 0)
# check sounds have been recorded
bisectMean <- aggregate(bisect_x~sound+jatosStudyResultId, length, data = bisectData)
View(bisectMean)
# then remove void trials
bisectData <- dplyr::filter(bisectData, void_trial == 0 & practice == 0)
# number of trials for each participant
ntrials <- aggregate(acc~jatosStudyResultId, length, data=bisectData)
# check sounds have been recorded
bisectMean <- aggregate(bisect_x~sound+jatosStudyResultId, length, data = bisectData)
